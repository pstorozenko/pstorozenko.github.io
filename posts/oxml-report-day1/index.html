<!doctype html><html lang=en><head><title>OxML Report Day 1 üìú ::
Pasza's blog ‚Äî a simple blog about complex things
</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="The report of all talks during the first day of OxML Health 2023 where I&amp;rsquo;ve been on behalf of Appsilon.
This day talks were on:
Casual Inference - Cheng Zhang Computer Vision in medicine - Jorge Cardoso Knowledge Representation - Ali Eslami "><meta name=keywords content="piotr pasza pasha storozenko ml data science machine learning"><meta name=robots content="noodp"><link rel=canonical href=/posts/oxml-report-day1/><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.css integrity=sha384-ysFyB7Is//Q1JNgERb0bLJokXKM8eWJsjEutGvthoHtBilHWgbdmbYkQZdwCIGIq crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.js integrity=sha384-UWjC+k927Mtx6WQF5SzKTXLLrOYmzs69HvkUjiKvUwSOljzc+C6PrGquNpOvJBBo crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/contrib/auto-render.min.js integrity=sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-PR8Z9SJC7F"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-PR8Z9SJC7F",{anonymize_ip:!1})}</script><link rel=stylesheet href=/assets/style.css><link rel=stylesheet href=/style.css><link rel=apple-touch-icon-precomposed sizes=144x144 href=/img/apple-touch-icon-144-precomposed.png><link rel="shortcut icon" href=/img/favicon.png><link href=/assets/fonts/Inter-Italic.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=/assets/fonts/Inter-Regular.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=/assets/fonts/Inter-Medium.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=/assets/fonts/Inter-MediumItalic.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=/assets/fonts/Inter-Bold.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=/assets/fonts/Inter-BoldItalic.woff2 rel=preload type=font/woff2 as=font crossorigin><meta name=twitter:card content="summary"><meta name=twitter:title content="OxML Report Day 1 üìú"><meta name=twitter:description content="The report of all talks during the first day of OxML Health 2023 where I&rsquo;ve been on behalf of Appsilon.
This day talks were on:

Casual Inference - Cheng Zhang
Computer Vision in medicine - Jorge Cardoso
Knowledge Representation - Ali Eslami
"><meta property="og:title" content="OxML Report Day 1 üìú"><meta property="og:description" content="The report of all talks during the first day of OxML Health 2023 where I&rsquo;ve been on behalf of Appsilon.
This day talks were on:

Casual Inference - Cheng Zhang
Computer Vision in medicine - Jorge Cardoso
Knowledge Representation - Ali Eslami
"><meta property="og:type" content="article"><meta property="og:url" content="/posts/oxml-report-day1/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-07-21T23:00:00+01:00"><meta property="article:modified_time" content="2023-07-21T23:00:00+01:00"></head><body class=light-theme><div class=container><header class=header><span class=header__inner><a href=/ class=logo style=text-decoration:none><span class=logo__mark><svg xmlns="http://www.w3.org/2000/svg" class="greater-icon" viewBox="0 0 44 44"><path fill="none" d="M15 8l14.729 14.382L15 35.367"/></svg>
</span><span class=logo__text>pasza's blog</span>
<span class=logo__cursor></span>
</a><span class=header__right><nav class=menu><ul class="menu__inner menu__inner--desktop"><li><a href=/about>About me</a></li><li><a href=/useful-materials>Useful materials</a></li></ul><ul class="menu__inner menu__inner--mobile"><li><a href=/about>About me</a></li><li><a href=/useful-materials>Useful materials</a></li></ul></nav><span class=menu-trigger><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M0 0h24v24H0z" fill="none"/><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg>
</span><span class=theme-toggle><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M22 41c10.4934.0 19-8.5066 19-19C41 11.5066 32.4934 3 22 3 11.5066 3 3 11.5066 3 22s8.5066 19 19 19zM7 22C7 13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22z"/></svg></span></span></span></header><div class=content><div class=post><h1 class=post-title>OxML Report Day 1 üìú</h1><div class=post-meta><span class=post-date>2023-07-21</span></div><span class=post-tags><a href=/tags/conference/>#conference</a>&nbsp;
<a href=/tags/oxml/>#OxML</a>&nbsp;
<a href=/tags/oxford/>#Oxford</a>&nbsp;
<a href=/tags/machine-learning/>#machine-learning</a>&nbsp;
<a href=/tags/appsilon/>#appsilon</a>&nbsp;</span><div class=post-content><p>The report of all talks during the first day of OxML Health 2023 where I&rsquo;ve been on behalf of <a href=https://appsilon.com/>Appsilon</a>.</p><p>This day talks were on:</p><ol><li>Casual Inference - <a href=https://www.microsoft.com/en-us/research/people/chezha/>Cheng Zhang</a></li><li>Computer Vision in medicine - <a href=https://www.kcl.ac.uk/people/jorge-cardoso>Jorge Cardoso</a></li><li>Knowledge Representation - <a href=http://arkitus.com/>Ali Eslami</a></li></ol><p>I understand it might be out-of-context for people not attending OxML.
If you&rsquo;re interested in something in particular, reach out to me on <a href=https://www.linkedin.com/in/piotr-pasza-storo%C5%BCenko/>LinkedIn</a>.</p><h2 id=causal-inference---cheng-zhang>Causal Inference - Cheng Zhang
<a href=#causal-inference---cheng-zhang class=h-anchor aria-hidden=true>#</a></h2><p>Cheng Zhang, a Principal Researcher at Microsoft Research, primarily focuses on Approximate Inference and Causal Machine Learning. Her presentation primarily revolved around integrating neural networks into classical Bayesian network inference schemas.</p><ol><li>She suggested that if we calculate some embeddings (in encoder-decoder networks) within our model, we can analyze latent variables instead of analyzing the decoded image/signal/&mldr;</li><li>A significant part of her presentation was dedicated to Bayesian methods centered around the ELBO (evidence lower bound). Although I found this portion a bit challenging to follow, it appeared that the concept of reinforced gradients with the gradient trick is crucial here. The formula given was $\frac{d}{dx}\log(f(x)) = \frac{1}{f(x)} \frac{d}{dx}f(x)$.</li><li>Zhang noted that KL divergence is just one form of the broader $\alpha$ divergence.</li><li>She offered an insightful comparison between GANs and VAE:<ul><li>VAE results are often blurry</li><li>GANs present unstable training</li><li>Before the advent of diffusion models, VAEs with numerous layers outperformed GANs</li><li>The introduction of diffusion models led to a significant improvement in results</li><li>Currently, diffusion models are at the forefront of this field</li><li>She briefly questioned the potential of normalized flows</li><li>The recent research interest is notably leaning towards GPT models</li></ul></li><li>The latter part of her talk pivoted towards causality, discussing causality discovery and causality inference.</li><li>Importantly, she highlighted that conducting A/B tests in medicine is not feasible.</li><li>Lastly, she mentioned their use of multi-to-multi modality models.</li></ol><h2 id=computer-vision-in-medicine---jorge-cardoso>Computer Vision in Medicine - Jorge Cardoso
<a href=#computer-vision-in-medicine---jorge-cardoso class=h-anchor aria-hidden=true>#</a></h2><p>Jorge Cardoso, a Reader in Artificial Medical Intelligence at King‚Äôs College London, shared his insights on the application of computer vision in the healthcare industry.</p><ol><li>He emphasized that the role of machine learning (ML) in medicine is not about making diagnoses, but rather about facilitating personalized knowledge discovery. The aim is to provide doctors with guidance, not to take over their diagnostic tasks.</li><li>He discussed the challenge of tracking certain body-related parameters in medicine. For instance, factors such as alcohol consumption can cause daily fluctuations in brain size, making it difficult to overlay and compare scans from different days.</li><li>Cardoso asserted that with high-quality data, simple models like logistic regression can yield impressive results.</li><li>He spoke about the substantial challenge posed by the analysis of CT/MRI scans. Given that a single object often comprises a 256x256x256 scan‚Äîequivalent to over ~5.3 of 1k RGB images‚Äîonly 1-3 such scans can fit on a standard 16GB GPU, indicating a considerable resource demand.</li><li>Many methods, he noted, rely on consulting experts about what they seek in patient scans/images.</li><li>He highlighted a significant potential for data compression, given that brain structures are generally similar.</li><li>Augmentation in the medical domain is a complex issue. While necessary due to data scarcity, many augmentation methods can degrade image quality. Issues such as scaling and contrast adjustments become critical when precise measurements and tissue differentiation are involved. Successful augmentation requires a process of trial and error and robust test sets.</li><li>Cardoso advised that to make a real impact, researchers must be willing to loosen data quality restrictions.</li><li>He pointed out that data acquisition methods can vary widely between hospitals and even between different devices within a single hospital, making data standardization crucial.</li><li>Prior assumptions can bias your models, which can be beneficial but should always be considered.</li><li>Cardoso noted that many doctors prioritize modeling uncertainty over explainability. He mentioned that while it&rsquo;s beneficial for models to understand their limitations, current ML algorithms struggle with predicting &ldquo;nothing,&rdquo; an issue known as &ldquo;blank image modeling&rdquo;. A potential solution involves creating an autoencoder/diffusion model to calculate encoding for the input image in latent space, and then comparing the latent distribution with that of training chest images.</li><li>He emphasized that the text data in hospitals often diverges significantly from regular language usage. Medical professionals tend to use specific language structures, make frequent typos, and use numerous abbreviations.</li><li>To create large models in hospitals, federated learning is required. During training, model weights are shared across hospitals, ensuring that data doesn&rsquo;t leave the hospital.</li><li>He stressed the advantage of using well-validated frameworks like <a href=https://monai.io/>MONAI</a> when aiming to deploy a model in a hospital. Those frameworks are much easier to get validation for.</li><li>Lastly, Cardoso presented the latent diffusion model (LDM) of brain CT that his team developed. Utilizing 100,000 different scans (256x256x256) of healthy brains, training took four months on 32 Nvidia A100 GPUs. He outlined the variety of applications of this model, including identifying suspicious regions in a scan, impainting them, and presenting comparative views to the doctor. He noted the importance of maintaining the 3D structure of the latents, rather than flattening them, as many methods that work in 2D fail in 3D. In my opinion it might be dangerous as it suggests that other parts of the brain are healthy.</li></ol><h2 id=knowledge-representation---ali-eslami>Knowledge Representation - Ali Eslami
<a href=#knowledge-representation---ali-eslami class=h-anchor aria-hidden=true>#</a></h2><p>Ali Eslami, Director and Principal Scientist at Google DeepMind in London, delivered an engaging and immensely inspirational talk on various aspects of knowledge representation.</p><ol><li>Ali started by relating the concept of inference to Plato‚Äôs allegory of the cave. Taking the example of a vase casting a shadow in a cave, he elaborated on how we might stop at recognizing the object from its silhouette, but also try to infer its color, weight, temperature, and even smell. Although such information is lost in the shadow, we can still attempt estimations using our prior knowledge.</li><li>He noted that in practice, knowledge representation often involves devising some sort of latent space, through techniques like:<ul><li>Autoencoder</li><li>GANs</li><li>VAE</li><li>Diffusion</li><li>Sequential autoencoders</li></ul></li><li>He pointed out that in many methods, the latent can be conditioned on various attributes like class, label, or style.</li><li>He discussed how disentangling different parts of the latent space can assign meaningful representations. For example, in a 100-length vector, the first 10 parameters could be used for camera position estimation, the next 20 for image scale, and the rest for image content.</li><li>Ali highlighted the distinct approach of NeRFs, where a network is trained to generate views from different angles for a single object, based on multiple images taken from different viewpoints.</li><li>He also examined the game-changing impact of AlphaFold and the challenges that remain to be addressed. The AlphaFold model predicts the 3D structure of a protein based on its amino acid sequence, which allows for the exploration of structural flexibility and rigidity. The next step is to model interactions between multiple proteins.</li><li>In discussing GANs, Ali drew a distinction based on their lack of reliance on likelihood methods and the absence of an encoder to the latent dimension in the basic setup. Despite describing the training of GANs as a nightmare, he emphasized that playing with a trained model is incredibly enjoyable.</li><li>An inspiring example he shared was the unsupervised training of doodling and painting via the SPIRAL model. The team trained an algorithm to draw a face using 20 Photoshop operations, which they then used to program a robot that could physically paint on paper.</li><li>Ali discussed how knowledge representation could be learned, such as by predicting image rotation or using contrastive learning. He gave an example of selecting two images, A and B, augmenting A twice, and then stating that A1 is similar to A2, but both are different from B. This approach requires careful data selection to avoid picking the same image or the same entity twice.</li><li>In his conclusion, Ali identified two key challenges that make artificial intelligence field hard:<ol><li>Categorization (Cheetah vs. Leopard vs. Jaguar)<ul><li>Subjective (this could be a subspecies, not a new species)</li><li>Truth is subjective and exists only in our mind</li><li>Representational form is clear (we work on images of animals taken from the side)</li></ul></li><li>Partial observability (Different images of the same tiger)<ul><li>Objective (it&rsquo;s either the same or different entity)</li><li>Truth exists in reality</li><li>Representational form is mostly unclear.</li></ul></li></ol></li></ol></div><div class=pagination><div class=pagination__title><span class=pagination__title-h>Read other posts</span><hr></div><div class=pagination__buttons><span class="button previous"><a href=/posts/oxml-report-day2/><span class=button__icon>‚Üê</span>
<span class=button__text>OxML Report Day2 üìú</span>
</a></span><span class="button next"><a href=/posts/oxml-summary/><span class=button__text>OxML Health 2023 - Summary üåçüìö‚ù§Ô∏è‚Äçü©π</span>
<span class=button__icon>‚Üí</span></a></span></div></div></div></div><footer class=footer><div class=footer__inner><div class="copyright copyright--user">Piotr Pasza Storo≈ºenko</div></div></footer><script src=/assets/main.js></script><script src=/assets/prism.js></script></div><script async src="https://www.googletagmanager.com/gtag/js?id=G-PR8Z9SJC7F"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-PR8Z9SJC7F",{anonymize_ip:!1})}</script></body></html>