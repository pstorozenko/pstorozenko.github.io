<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>pytorch on Pasza's blog</title><link>/tags/pytorch/</link><description>Recent content in pytorch on Pasza's blog</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Piotr Pasza Storo≈ºenko</copyright><lastBuildDate>Thu, 07 Jul 2022 20:52:14 +0200</lastBuildDate><atom:link href="/tags/pytorch/index.xml" rel="self" type="application/rss+xml"/><item><title>PyTorch Serialization üì¶‚öôÔ∏è</title><link>/posts/pytorch-serialization/</link><pubDate>Thu, 07 Jul 2022 20:52:14 +0200</pubDate><guid>/posts/pytorch-serialization/</guid><description>
&lt;p>One thing is to train the model, but another is to serve it.
In between those two phases, model serialization and deserialization occurs.
In simpler words it&amp;rsquo;s just model saving and loading.
It&amp;rsquo;s important because different methods result in different:&lt;/p>
&lt;ol>
&lt;li>Inference speed&lt;/li>
&lt;li>Model size&lt;/li>
&lt;li>Python environment size&lt;/li>
&lt;/ol>
&lt;p>If you are curious what are the ways to serialize model in PyTorch and how they compare, checkout my &lt;a href="https://appsilon.com/model-serialization-in-machine-learning/">new post on Appsilon blog&lt;/a>.&lt;/p></description></item><item><title>PyTorch-Lightning + Hydra to Boost Your PyTorch ‚ö°üêâ</title><link>/posts/pytorch-hydra/</link><pubDate>Thu, 09 Jun 2022 00:38:25 +0200</pubDate><guid>/posts/pytorch-hydra/</guid><description>
When working with deep learning problems I usually use PyTorch. I like this framework as it gives me a lot of freedom and allows to write code in the pythonic way. Using bare pytorch unfortunately often means writing a lot of boilerplate code, which no-one like. Another problem that arises during longer and larger projects is experiments running and configuration maintenance. I tackle those two problems by using pytorch-lightning and Hydra.</description></item></channel></rss>